{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM-Det: Deepfake Detection - AI Factory ì œì¶œìš©\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ MM-Det ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë”¥í˜ì´í¬ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ë¥¼ ê°ì§€í•˜ê³  AI Factoryì— ì œì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“‹ ì œì¶œ ê·œì¹™\n",
    "- í‰ê°€ ë°ì´í„°: `./data/` ê²½ë¡œì— ì´ë¯¸ì§€(JPG, PNG)ì™€ ë™ì˜ìƒ(MP4) í˜¼í•©\n",
    "- ê²°ê³¼ íŒŒì¼: `submission.csv` (filename, label)\n",
    "- label: real=0, fake=1\n",
    "- ìµœëŒ€ ì¶”ë¡  ì‹œê°„: 3ì‹œê°„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# AI Factory ì œì¶œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def run_pip(args):\n",
    "    \"\"\"pip ëª…ë ¹ì–´ë¥¼ subprocessë¡œ ì‹¤í–‰\"\"\"\n",
    "    cmd = [sys.executable, '-m', 'pip'] + args\n",
    "    subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "# AI Factory ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "run_pip(['install', '-q', 'aifactory'])\n",
    "\n",
    "# NumPy ë‹¤ìš´ê·¸ë ˆì´ë“œ\n",
    "run_pip(['install', '-q', 'numpy<2.0'])\n",
    "\n",
    "# PyTorch ì„¤ì¹˜ (CUDA 11.8)\n",
    "run_pip(['install', '-q', 'torch', 'torchvision', 'torchaudio', '--index-url', 'https://download.pytorch.org/whl/cu118'])\n",
    "\n",
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "run_pip(['install', '-q', 'pandas', 'tqdm', 'pillow', 'opencv-python<4.10', 'scikit-learn', 'scikit-image', 'scipy'])\n",
    "run_pip(['install', '-q', 'transformers==4.37.2', 'tokenizers==0.15.1', 'sentencepiece==0.1.99'])\n",
    "run_pip(['install', '-q', 'accelerate==0.21.0', 'peft==0.10.0', '--no-deps'])\n",
    "run_pip(['install', '-q', 'timm==0.9.16', 'einops==0.6.1', 'einops-exts==0.0.4'])\n",
    "run_pip(['install', '-q', 'tensorboardX', 'imageio', 'huggingface-hub', 'safetensors'])\n",
    "run_pip(['install', '-q', 'protobuf==3.20.3', 'psutil', 'packaging'])\n",
    "\n",
    "# LLaVA íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "run_pip(['install', '-q', '-e', './LLaVA'])\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLaVA íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaVA ê²½ë¡œ ë°œê²¬: /workspace/MM-Det/LLaVA\n",
      "âœ… LLaVA ì„¤ì¹˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# LLaVA íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "project_root = os.getcwd()\n",
    "llava_path = os.path.join(project_root, 'LLaVA')\n",
    "\n",
    "if os.path.exists(llava_path):\n",
    "    print(f\"LLaVA ê²½ë¡œ ë°œê²¬: {llava_path}\")\n",
    "    # subprocessë¥¼ ì‚¬ìš©í•˜ì—¬ ì…¸ ëª…ë ¹ì–´ ì‹¤í–‰\n",
    "    result = subprocess.run(\n",
    "        ['pip', 'install', '-q', '-e', '.'],\n",
    "        cwd=llava_path,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… LLaVA ì„¤ì¹˜ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ LLaVA ì„¤ì¹˜ ì‹¤íŒ¨: {result.stderr}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ LLaVA ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {llava_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë¼ì´ë¸ŒëŸ¬ë¦¬ Import ë° í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MM-Det Deepfake Detection System\n",
      "================================================================================\n",
      "PyTorch: 2.8.0+cu128\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.8\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# bitsandbytes ë¹„í™œì„±í™” (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ) - transformers/accelerate import ì „ì— ì„¤ì •\n",
    "os.environ['DISABLE_BNB'] = '1'\n",
    "\n",
    "# bitsandbytes mock (import ì—ëŸ¬ ë°©ì§€)\n",
    "class MockBNB:\n",
    "    def __getattr__(self, name):\n",
    "        return lambda *args, **kwargs: None\n",
    "\n",
    "sys.modules['bitsandbytes'] = MockBNB()\n",
    "sys.modules['bitsandbytes.nn'] = MockBNB()\n",
    "\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# LLaVA ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€ (ì¤‘ìš”!)\n",
    "llava_path = os.path.join(project_root, 'LLaVA')\n",
    "if llava_path not in sys.path and os.path.exists(llava_path):\n",
    "    sys.path.insert(0, llava_path)\n",
    "    print(f\"âœ… LLaVA ê²½ë¡œ ì¶”ê°€: {llava_path}\")\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import\n",
    "from models import MMDet\n",
    "from utils.utils import set_random_seed\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MM-Det Deepfake Detection System\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì„¤ì • (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • ì™„ë£Œ\n",
      "ë°ì´í„° ê²½ë¡œ: ./data\n",
      "ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸: ./weights/MM-Det/current_model.pth\n",
      "ViT ì²´í¬í¬ì¸íŠ¸: ./weights/ViT/vit_base_r50_s16_224.orig_in21k/jx_vit_base_resnet50_224_in21k-6f7c7740.pth\n",
      "Window size: 10\n",
      "ì œì¶œ íŒŒì¼: ./submission.csv\n",
      "config_dict keys: 23\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì •\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # ë°ì´í„° ê²½ë¡œ (AI Factory ê·œì¹™)\n",
    "        self.data_dir = './data'  # í‰ê°€ ë°ì´í„° ê²½ë¡œ\n",
    "        self.output_path = './submission.csv'  # ì œì¶œ íŒŒì¼ ê²½ë¡œ\n",
    "        \n",
    "        # ëª¨ë¸ ê²½ë¡œ (ìƒëŒ€ ê²½ë¡œ)\n",
    "        self.model_dir = './model/deep-fake-detector-v2-model'\n",
    "        self.ckpt = './weights/MM-Det/current_model.pth'\n",
    "        \n",
    "        # LMM ì„¤ì •\n",
    "        self.lmm_ckpt = './llava-7b-1.5-rfrd'\n",
    "        self.lmm_base = None  # ì „ì²´ ëª¨ë¸ì„ lmm_ckptì—ì„œ ë¡œë“œ\n",
    "        self.cache_mm = True\n",
    "        self.mm_root = None  # ìºì‹œ ì‚¬ìš© ì•ˆí•¨ (í‰ê°€ ë°ì´í„°)\n",
    "        \n",
    "        # ST ë¸Œëœì¹˜ ì„¤ì •\n",
    "        self.st_ckpt = './weights/ViT/vit_base_r50_s16_224.orig_in21k/jx_vit_base_resnet50_224_in21k-6f7c7740.pth'\n",
    "        self.st_pretrained = False\n",
    "        \n",
    "        # ëª¨ë¸ íŒŒë¼ë¯¸í„°\n",
    "        self.model_name = 'MM-Det'\n",
    "        self.window_size = 10  # ì²´í¬í¬ì¸íŠ¸ì™€ ë§ì¶¤ (10, not 16!)\n",
    "        self.conv_mode = 'vicuna_v1'\n",
    "        self.new_tokens = 256\n",
    "        self.selected_layers = [8, 16, 24]\n",
    "        self.interval = 1\n",
    "        \n",
    "        # ì¶”ë¡  ì„¤ì •\n",
    "        self.seed = 42\n",
    "        self.gpus = 1\n",
    "        self.batch_size = 4  # GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •\n",
    "        self.device = 'cuda'\n",
    "        \n",
    "        # ì–‘ìí™” (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "        self.load_8bit = False\n",
    "        self.load_4bit = False\n",
    "        \n",
    "        self.debug = False\n",
    "\n",
    "config = Config()\n",
    "config_dict = {k: v for k, v in config.__dict__.items() if not k.startswith('_')}\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ì„¤ì •\n",
    "set_random_seed(config.seed)\n",
    "\n",
    "print(\"âœ… ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ë°ì´í„° ê²½ë¡œ: {config.data_dir}\")\n",
    "print(f\"ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸: {config.ckpt}\")\n",
    "print(f\"ViT ì²´í¬í¬ì¸íŠ¸: {config.st_ckpt}\")\n",
    "print(f\"Window size: {config.window_size}\")\n",
    "print(f\"ì œì¶œ íŒŒì¼: {config.output_path}\")\n",
    "print(f\"config_dict keys: {len(config_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. í‰ê°€ ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "í‰ê°€ ë°ì´í„° í™•ì¸\n",
      "================================================================================\n",
      "ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: 0\n",
      "ë¹„ë””ì˜¤ íŒŒì¼ ìˆ˜: 0\n",
      "ì „ì²´ íŒŒì¼ ìˆ˜: 0\n",
      "================================================================================\n",
      "âš ï¸ ê²½ê³ : ./dataì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€ ë°ì´í„° íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "data_dir = Path(config.data_dir)\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
    "image_files = []\n",
    "for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "    image_files.extend(list(data_dir.glob(ext)))\n",
    "\n",
    "# ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°\n",
    "video_files = []\n",
    "for ext in ['*.mp4', '*.MP4', '*.avi', '*.AVI', '*.mov', '*.MOV']:\n",
    "    video_files.extend(list(data_dir.glob(ext)))\n",
    "\n",
    "all_files = image_files + video_files\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"í‰ê°€ ë°ì´í„° í™•ì¸\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {len(image_files)}\")\n",
    "print(f\"ë¹„ë””ì˜¤ íŒŒì¼ ìˆ˜: {len(video_files)}\")\n",
    "print(f\"ì „ì²´ íŒŒì¼ ìˆ˜: {len(all_files)}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    print(f\"âš ï¸ ê²½ê³ : {config.data_dir}ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ìƒ˜í”Œ íŒŒì¼:\")\n",
    "    for f in all_files[:5]:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ëª¨ë¸ ë¡œë”© ì‹œì‘...\n",
      "================================================================================\n",
      "Missing keys (fc_token, window_pos_embed, temporal_pos_embed, time_embed, patch_embed.rgb_backbone.stem.conv.weight, patch_embed.rgb_backbone.stem.norm.weight, patch_embed.rgb_backbone.stem.norm.bias, patch_embed.rgb_backbone.freq_stem.conv.weight, patch_embed.rgb_backbone.freq_stem.norm.weight, patch_embed.rgb_backbone.freq_stem.norm.bias, patch_embed.rgb_backbone.stems_transition_conv_1x1.0.weight, patch_embed.rgb_backbone.stems_transition_conv_1x1.1.weight, patch_embed.rgb_backbone.stems_transition_conv_1x1.1.bias, patch_embed.rgb_backbone.stems_transition_conv_1x1.1.running_mean, patch_embed.rgb_backbone.stems_transition_conv_1x1.1.running_var, patch_embed.rgb_backbone.stages.0.blocks.0.downsample.conv.weight, patch_embed.rgb_backbone.stages.0.blocks.0.downsample.norm.weight, patch_embed.rgb_backbone.stages.0.blocks.0.downsample.norm.bias, patch_embed.rgb_backbone.stages.0.blocks.0.conv1.weight, patch_embed.rgb_backbone.stages.0.blocks.0.norm1.weight, patch_embed.rgb_backbone.stages.0.blocks.0.norm1.bias, patch_embed.rgb_backbone.stages.0.blocks.0.conv2.weight, patch_embed.rgb_backbone.stages.0.blocks.0.norm2.weight, patch_embed.rgb_backbone.stages.0.blocks.0.norm2.bias, patch_embed.rgb_backbone.stages.0.blocks.0.conv3.weight, patch_embed.rgb_backbone.stages.0.blocks.0.norm3.weight, patch_embed.rgb_backbone.stages.0.blocks.0.norm3.bias, patch_embed.rgb_backbone.stages.0.blocks.1.conv1.weight, patch_embed.rgb_backbone.stages.0.blocks.1.norm1.weight, patch_embed.rgb_backbone.stages.0.blocks.1.norm1.bias, patch_embed.rgb_backbone.stages.0.blocks.1.conv2.weight, patch_embed.rgb_backbone.stages.0.blocks.1.norm2.weight, patch_embed.rgb_backbone.stages.0.blocks.1.norm2.bias, patch_embed.rgb_backbone.stages.0.blocks.1.conv3.weight, patch_embed.rgb_backbone.stages.0.blocks.1.norm3.weight, patch_embed.rgb_backbone.stages.0.blocks.1.norm3.bias, patch_embed.rgb_backbone.stages.0.blocks.2.conv1.weight, patch_embed.rgb_backbone.stages.0.blocks.2.norm1.weight, patch_embed.rgb_backbone.stages.0.blocks.2.norm1.bias, patch_embed.rgb_backbone.stages.0.blocks.2.conv2.weight, patch_embed.rgb_backbone.stages.0.blocks.2.norm2.weight, patch_embed.rgb_backbone.stages.0.blocks.2.norm2.bias, patch_embed.rgb_backbone.stages.0.blocks.2.conv3.weight, patch_embed.rgb_backbone.stages.0.blocks.2.norm3.weight, patch_embed.rgb_backbone.stages.0.blocks.2.norm3.bias, patch_embed.rgb_backbone.stages.1.blocks.0.downsample.conv.weight, patch_embed.rgb_backbone.stages.1.blocks.0.downsample.norm.weight, patch_embed.rgb_backbone.stages.1.blocks.0.downsample.norm.bias, patch_embed.rgb_backbone.stages.1.blocks.0.conv1.weight, patch_embed.rgb_backbone.stages.1.blocks.0.norm1.weight, patch_embed.rgb_backbone.stages.1.blocks.0.norm1.bias, patch_embed.rgb_backbone.stages.1.blocks.0.conv2.weight, patch_embed.rgb_backbone.stages.1.blocks.0.norm2.weight, patch_embed.rgb_backbone.stages.1.blocks.0.norm2.bias, patch_embed.rgb_backbone.stages.1.blocks.0.conv3.weight, patch_embed.rgb_backbone.stages.1.blocks.0.norm3.weight, patch_embed.rgb_backbone.stages.1.blocks.0.norm3.bias, patch_embed.rgb_backbone.stages.1.blocks.1.conv1.weight, patch_embed.rgb_backbone.stages.1.blocks.1.norm1.weight, patch_embed.rgb_backbone.stages.1.blocks.1.norm1.bias, patch_embed.rgb_backbone.stages.1.blocks.1.conv2.weight, patch_embed.rgb_backbone.stages.1.blocks.1.norm2.weight, patch_embed.rgb_backbone.stages.1.blocks.1.norm2.bias, patch_embed.rgb_backbone.stages.1.blocks.1.conv3.weight, patch_embed.rgb_backbone.stages.1.blocks.1.norm3.weight, patch_embed.rgb_backbone.stages.1.blocks.1.norm3.bias, patch_embed.rgb_backbone.stages.1.blocks.2.conv1.weight, patch_embed.rgb_backbone.stages.1.blocks.2.norm1.weight, patch_embed.rgb_backbone.stages.1.blocks.2.norm1.bias, patch_embed.rgb_backbone.stages.1.blocks.2.conv2.weight, patch_embed.rgb_backbone.stages.1.blocks.2.norm2.weight, patch_embed.rgb_backbone.stages.1.blocks.2.norm2.bias, patch_embed.rgb_backbone.stages.1.blocks.2.conv3.weight, patch_embed.rgb_backbone.stages.1.blocks.2.norm3.weight, patch_embed.rgb_backbone.stages.1.blocks.2.norm3.bias, patch_embed.rgb_backbone.stages.1.blocks.3.conv1.weight, patch_embed.rgb_backbone.stages.1.blocks.3.norm1.weight, patch_embed.rgb_backbone.stages.1.blocks.3.norm1.bias, patch_embed.rgb_backbone.stages.1.blocks.3.conv2.weight, patch_embed.rgb_backbone.stages.1.blocks.3.norm2.weight, patch_embed.rgb_backbone.stages.1.blocks.3.norm2.bias, patch_embed.rgb_backbone.stages.1.blocks.3.conv3.weight, patch_embed.rgb_backbone.stages.1.blocks.3.norm3.weight, patch_embed.rgb_backbone.stages.1.blocks.3.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.0.downsample.conv.weight, patch_embed.rgb_backbone.stages.2.blocks.0.downsample.norm.weight, patch_embed.rgb_backbone.stages.2.blocks.0.downsample.norm.bias, patch_embed.rgb_backbone.stages.2.blocks.0.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.0.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.0.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.0.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.0.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.0.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.0.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.0.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.0.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.1.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.1.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.1.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.1.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.1.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.1.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.1.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.1.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.1.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.2.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.2.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.2.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.2.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.2.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.2.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.2.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.2.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.2.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.3.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.3.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.3.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.3.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.3.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.3.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.3.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.3.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.3.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.4.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.4.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.4.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.4.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.4.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.4.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.4.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.4.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.4.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.5.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.5.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.5.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.5.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.5.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.5.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.5.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.5.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.5.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.6.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.6.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.6.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.6.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.6.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.6.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.6.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.6.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.6.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.7.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.7.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.7.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.7.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.7.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.7.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.7.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.7.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.7.norm3.bias, patch_embed.rgb_backbone.stages.2.blocks.8.conv1.weight, patch_embed.rgb_backbone.stages.2.blocks.8.norm1.weight, patch_embed.rgb_backbone.stages.2.blocks.8.norm1.bias, patch_embed.rgb_backbone.stages.2.blocks.8.conv2.weight, patch_embed.rgb_backbone.stages.2.blocks.8.norm2.weight, patch_embed.rgb_backbone.stages.2.blocks.8.norm2.bias, patch_embed.rgb_backbone.stages.2.blocks.8.conv3.weight, patch_embed.rgb_backbone.stages.2.blocks.8.norm3.weight, patch_embed.rgb_backbone.stages.2.blocks.8.norm3.bias, patch_embed.rgb_backbone.freq_stage.blocks.0.downsample.conv.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.downsample.norm.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.downsample.norm.bias, patch_embed.rgb_backbone.freq_stage.blocks.0.conv1.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.norm1.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.norm1.bias, patch_embed.rgb_backbone.freq_stage.blocks.0.conv2.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.norm2.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.norm2.bias, patch_embed.rgb_backbone.freq_stage.blocks.0.conv3.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.norm3.weight, patch_embed.rgb_backbone.freq_stage.blocks.0.norm3.bias, patch_embed.rgb_backbone.freq_stage.blocks.1.conv1.weight, patch_embed.rgb_backbone.freq_stage.blocks.1.norm1.weight, patch_embed.rgb_backbone.freq_stage.blocks.1.norm1.bias, patch_embed.rgb_backbone.freq_stage.blocks.1.conv2.weight, patch_embed.rgb_backbone.freq_stage.blocks.1.norm2.weight, patch_embed.rgb_backbone.freq_stage.blocks.1.norm2.bias, patch_embed.rgb_backbone.freq_stage.blocks.1.conv3.weight, patch_embed.rgb_backbone.freq_stage.blocks.1.norm3.weight, patch_embed.rgb_backbone.freq_stage.blocks.1.norm3.bias, patch_embed.rgb_backbone.freq_stage.blocks.2.conv1.weight, patch_embed.rgb_backbone.freq_stage.blocks.2.norm1.weight, patch_embed.rgb_backbone.freq_stage.blocks.2.norm1.bias, patch_embed.rgb_backbone.freq_stage.blocks.2.conv2.weight, patch_embed.rgb_backbone.freq_stage.blocks.2.norm2.weight, patch_embed.rgb_backbone.freq_stage.blocks.2.norm2.bias, patch_embed.rgb_backbone.freq_stage.blocks.2.conv3.weight, patch_embed.rgb_backbone.freq_stage.blocks.2.norm3.weight, patch_embed.rgb_backbone.freq_stage.blocks.2.norm3.bias, patch_embed.recons_backbone.stem.conv.weight, patch_embed.recons_backbone.stem.norm.weight, patch_embed.recons_backbone.stem.norm.bias, patch_embed.recons_backbone.freq_stem.conv.weight, patch_embed.recons_backbone.freq_stem.norm.weight, patch_embed.recons_backbone.freq_stem.norm.bias, patch_embed.recons_backbone.stems_transition_conv_1x1.0.weight, patch_embed.recons_backbone.stems_transition_conv_1x1.1.weight, patch_embed.recons_backbone.stems_transition_conv_1x1.1.bias, patch_embed.recons_backbone.stems_transition_conv_1x1.1.running_mean, patch_embed.recons_backbone.stems_transition_conv_1x1.1.running_var, patch_embed.recons_backbone.stages.0.blocks.0.downsample.conv.weight, patch_embed.recons_backbone.stages.0.blocks.0.downsample.norm.weight, patch_embed.recons_backbone.stages.0.blocks.0.downsample.norm.bias, patch_embed.recons_backbone.stages.0.blocks.0.conv1.weight, patch_embed.recons_backbone.stages.0.blocks.0.norm1.weight, patch_embed.recons_backbone.stages.0.blocks.0.norm1.bias, patch_embed.recons_backbone.stages.0.blocks.0.conv2.weight, patch_embed.recons_backbone.stages.0.blocks.0.norm2.weight, patch_embed.recons_backbone.stages.0.blocks.0.norm2.bias, patch_embed.recons_backbone.stages.0.blocks.0.conv3.weight, patch_embed.recons_backbone.stages.0.blocks.0.norm3.weight, patch_embed.recons_backbone.stages.0.blocks.0.norm3.bias, patch_embed.recons_backbone.stages.0.blocks.1.conv1.weight, patch_embed.recons_backbone.stages.0.blocks.1.norm1.weight, patch_embed.recons_backbone.stages.0.blocks.1.norm1.bias, patch_embed.recons_backbone.stages.0.blocks.1.conv2.weight, patch_embed.recons_backbone.stages.0.blocks.1.norm2.weight, patch_embed.recons_backbone.stages.0.blocks.1.norm2.bias, patch_embed.recons_backbone.stages.0.blocks.1.conv3.weight, patch_embed.recons_backbone.stages.0.blocks.1.norm3.weight, patch_embed.recons_backbone.stages.0.blocks.1.norm3.bias, patch_embed.recons_backbone.stages.0.blocks.2.conv1.weight, patch_embed.recons_backbone.stages.0.blocks.2.norm1.weight, patch_embed.recons_backbone.stages.0.blocks.2.norm1.bias, patch_embed.recons_backbone.stages.0.blocks.2.conv2.weight, patch_embed.recons_backbone.stages.0.blocks.2.norm2.weight, patch_embed.recons_backbone.stages.0.blocks.2.norm2.bias, patch_embed.recons_backbone.stages.0.blocks.2.conv3.weight, patch_embed.recons_backbone.stages.0.blocks.2.norm3.weight, patch_embed.recons_backbone.stages.0.blocks.2.norm3.bias, patch_embed.recons_backbone.stages.1.blocks.0.downsample.conv.weight, patch_embed.recons_backbone.stages.1.blocks.0.downsample.norm.weight, patch_embed.recons_backbone.stages.1.blocks.0.downsample.norm.bias, patch_embed.recons_backbone.stages.1.blocks.0.conv1.weight, patch_embed.recons_backbone.stages.1.blocks.0.norm1.weight, patch_embed.recons_backbone.stages.1.blocks.0.norm1.bias, patch_embed.recons_backbone.stages.1.blocks.0.conv2.weight, patch_embed.recons_backbone.stages.1.blocks.0.norm2.weight, patch_embed.recons_backbone.stages.1.blocks.0.norm2.bias, patch_embed.recons_backbone.stages.1.blocks.0.conv3.weight, patch_embed.recons_backbone.stages.1.blocks.0.norm3.weight, patch_embed.recons_backbone.stages.1.blocks.0.norm3.bias, patch_embed.recons_backbone.stages.1.blocks.1.conv1.weight, patch_embed.recons_backbone.stages.1.blocks.1.norm1.weight, patch_embed.recons_backbone.stages.1.blocks.1.norm1.bias, patch_embed.recons_backbone.stages.1.blocks.1.conv2.weight, patch_embed.recons_backbone.stages.1.blocks.1.norm2.weight, patch_embed.recons_backbone.stages.1.blocks.1.norm2.bias, patch_embed.recons_backbone.stages.1.blocks.1.conv3.weight, patch_embed.recons_backbone.stages.1.blocks.1.norm3.weight, patch_embed.recons_backbone.stages.1.blocks.1.norm3.bias, patch_embed.recons_backbone.stages.1.blocks.2.conv1.weight, patch_embed.recons_backbone.stages.1.blocks.2.norm1.weight, patch_embed.recons_backbone.stages.1.blocks.2.norm1.bias, patch_embed.recons_backbone.stages.1.blocks.2.conv2.weight, patch_embed.recons_backbone.stages.1.blocks.2.norm2.weight, patch_embed.recons_backbone.stages.1.blocks.2.norm2.bias, patch_embed.recons_backbone.stages.1.blocks.2.conv3.weight, patch_embed.recons_backbone.stages.1.blocks.2.norm3.weight, patch_embed.recons_backbone.stages.1.blocks.2.norm3.bias, patch_embed.recons_backbone.stages.1.blocks.3.conv1.weight, patch_embed.recons_backbone.stages.1.blocks.3.norm1.weight, patch_embed.recons_backbone.stages.1.blocks.3.norm1.bias, patch_embed.recons_backbone.stages.1.blocks.3.conv2.weight, patch_embed.recons_backbone.stages.1.blocks.3.norm2.weight, patch_embed.recons_backbone.stages.1.blocks.3.norm2.bias, patch_embed.recons_backbone.stages.1.blocks.3.conv3.weight, patch_embed.recons_backbone.stages.1.blocks.3.norm3.weight, patch_embed.recons_backbone.stages.1.blocks.3.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.0.downsample.conv.weight, patch_embed.recons_backbone.stages.2.blocks.0.downsample.norm.weight, patch_embed.recons_backbone.stages.2.blocks.0.downsample.norm.bias, patch_embed.recons_backbone.stages.2.blocks.0.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.0.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.0.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.0.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.0.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.0.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.0.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.0.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.0.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.1.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.1.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.1.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.1.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.1.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.1.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.1.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.1.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.1.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.2.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.2.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.2.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.2.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.2.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.2.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.2.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.2.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.2.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.3.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.3.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.3.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.3.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.3.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.3.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.3.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.3.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.3.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.4.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.4.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.4.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.4.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.4.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.4.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.4.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.4.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.4.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.5.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.5.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.5.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.5.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.5.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.5.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.5.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.5.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.5.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.6.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.6.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.6.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.6.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.6.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.6.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.6.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.6.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.6.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.7.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.7.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.7.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.7.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.7.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.7.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.7.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.7.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.7.norm3.bias, patch_embed.recons_backbone.stages.2.blocks.8.conv1.weight, patch_embed.recons_backbone.stages.2.blocks.8.norm1.weight, patch_embed.recons_backbone.stages.2.blocks.8.norm1.bias, patch_embed.recons_backbone.stages.2.blocks.8.conv2.weight, patch_embed.recons_backbone.stages.2.blocks.8.norm2.weight, patch_embed.recons_backbone.stages.2.blocks.8.norm2.bias, patch_embed.recons_backbone.stages.2.blocks.8.conv3.weight, patch_embed.recons_backbone.stages.2.blocks.8.norm3.weight, patch_embed.recons_backbone.stages.2.blocks.8.norm3.bias, patch_embed.recons_backbone.freq_stage.blocks.0.downsample.conv.weight, patch_embed.recons_backbone.freq_stage.blocks.0.downsample.norm.weight, patch_embed.recons_backbone.freq_stage.blocks.0.downsample.norm.bias, patch_embed.recons_backbone.freq_stage.blocks.0.conv1.weight, patch_embed.recons_backbone.freq_stage.blocks.0.norm1.weight, patch_embed.recons_backbone.freq_stage.blocks.0.norm1.bias, patch_embed.recons_backbone.freq_stage.blocks.0.conv2.weight, patch_embed.recons_backbone.freq_stage.blocks.0.norm2.weight, patch_embed.recons_backbone.freq_stage.blocks.0.norm2.bias, patch_embed.recons_backbone.freq_stage.blocks.0.conv3.weight, patch_embed.recons_backbone.freq_stage.blocks.0.norm3.weight, patch_embed.recons_backbone.freq_stage.blocks.0.norm3.bias, patch_embed.recons_backbone.freq_stage.blocks.1.conv1.weight, patch_embed.recons_backbone.freq_stage.blocks.1.norm1.weight, patch_embed.recons_backbone.freq_stage.blocks.1.norm1.bias, patch_embed.recons_backbone.freq_stage.blocks.1.conv2.weight, patch_embed.recons_backbone.freq_stage.blocks.1.norm2.weight, patch_embed.recons_backbone.freq_stage.blocks.1.norm2.bias, patch_embed.recons_backbone.freq_stage.blocks.1.conv3.weight, patch_embed.recons_backbone.freq_stage.blocks.1.norm3.weight, patch_embed.recons_backbone.freq_stage.blocks.1.norm3.bias, patch_embed.recons_backbone.freq_stage.blocks.2.conv1.weight, patch_embed.recons_backbone.freq_stage.blocks.2.norm1.weight, patch_embed.recons_backbone.freq_stage.blocks.2.norm1.bias, patch_embed.recons_backbone.freq_stage.blocks.2.conv2.weight, patch_embed.recons_backbone.freq_stage.blocks.2.norm2.weight, patch_embed.recons_backbone.freq_stage.blocks.2.norm2.bias, patch_embed.recons_backbone.freq_stage.blocks.2.conv3.weight, patch_embed.recons_backbone.freq_stage.blocks.2.norm3.weight, patch_embed.recons_backbone.freq_stage.blocks.2.norm3.bias, patch_embed.transition.0.weight, patch_embed.transition.0.bias, patch_embed.transition.1.weight, patch_embed.transition.1.bias, patch_embed.transition.1.running_mean, patch_embed.transition.1.running_var, blocks.0.temporal_norm1.weight, blocks.0.temporal_norm1.bias, blocks.0.temporal_attn.qkv.weight, blocks.0.temporal_attn.qkv.bias, blocks.0.temporal_attn.proj.weight, blocks.0.temporal_attn.proj.bias, blocks.0.temporal_norm2.weight, blocks.0.temporal_norm2.bias, blocks.0.temporal_mlp.fc1.weight, blocks.0.temporal_mlp.fc1.bias, blocks.0.temporal_mlp.fc2.weight, blocks.0.temporal_mlp.fc2.bias, blocks.1.temporal_norm1.weight, blocks.1.temporal_norm1.bias, blocks.1.temporal_attn.qkv.weight, blocks.1.temporal_attn.qkv.bias, blocks.1.temporal_attn.proj.weight, blocks.1.temporal_attn.proj.bias, blocks.1.temporal_norm2.weight, blocks.1.temporal_norm2.bias, blocks.1.temporal_mlp.fc1.weight, blocks.1.temporal_mlp.fc1.bias, blocks.1.temporal_mlp.fc2.weight, blocks.1.temporal_mlp.fc2.bias, blocks.2.temporal_norm1.weight, blocks.2.temporal_norm1.bias, blocks.2.temporal_attn.qkv.weight, blocks.2.temporal_attn.qkv.bias, blocks.2.temporal_attn.proj.weight, blocks.2.temporal_attn.proj.bias, blocks.2.temporal_norm2.weight, blocks.2.temporal_norm2.bias, blocks.2.temporal_mlp.fc1.weight, blocks.2.temporal_mlp.fc1.bias, blocks.2.temporal_mlp.fc2.weight, blocks.2.temporal_mlp.fc2.bias, blocks.3.temporal_norm1.weight, blocks.3.temporal_norm1.bias, blocks.3.temporal_attn.qkv.weight, blocks.3.temporal_attn.qkv.bias, blocks.3.temporal_attn.proj.weight, blocks.3.temporal_attn.proj.bias, blocks.3.temporal_norm2.weight, blocks.3.temporal_norm2.bias, blocks.3.temporal_mlp.fc1.weight, blocks.3.temporal_mlp.fc1.bias, blocks.3.temporal_mlp.fc2.weight, blocks.3.temporal_mlp.fc2.bias, blocks.4.temporal_norm1.weight, blocks.4.temporal_norm1.bias, blocks.4.temporal_attn.qkv.weight, blocks.4.temporal_attn.qkv.bias, blocks.4.temporal_attn.proj.weight, blocks.4.temporal_attn.proj.bias, blocks.4.temporal_norm2.weight, blocks.4.temporal_norm2.bias, blocks.4.temporal_mlp.fc1.weight, blocks.4.temporal_mlp.fc1.bias, blocks.4.temporal_mlp.fc2.weight, blocks.4.temporal_mlp.fc2.bias, blocks.5.temporal_norm1.weight, blocks.5.temporal_norm1.bias, blocks.5.temporal_attn.qkv.weight, blocks.5.temporal_attn.qkv.bias, blocks.5.temporal_attn.proj.weight, blocks.5.temporal_attn.proj.bias, blocks.5.temporal_norm2.weight, blocks.5.temporal_norm2.bias, blocks.5.temporal_mlp.fc1.weight, blocks.5.temporal_mlp.fc1.bias, blocks.5.temporal_mlp.fc2.weight, blocks.5.temporal_mlp.fc2.bias, blocks.6.temporal_norm1.weight, blocks.6.temporal_norm1.bias, blocks.6.temporal_attn.qkv.weight, blocks.6.temporal_attn.qkv.bias, blocks.6.temporal_attn.proj.weight, blocks.6.temporal_attn.proj.bias, blocks.6.temporal_norm2.weight, blocks.6.temporal_norm2.bias, blocks.6.temporal_mlp.fc1.weight, blocks.6.temporal_mlp.fc1.bias, blocks.6.temporal_mlp.fc2.weight, blocks.6.temporal_mlp.fc2.bias, blocks.7.temporal_norm1.weight, blocks.7.temporal_norm1.bias, blocks.7.temporal_attn.qkv.weight, blocks.7.temporal_attn.qkv.bias, blocks.7.temporal_attn.proj.weight, blocks.7.temporal_attn.proj.bias, blocks.7.temporal_norm2.weight, blocks.7.temporal_norm2.bias, blocks.7.temporal_mlp.fc1.weight, blocks.7.temporal_mlp.fc1.bias, blocks.7.temporal_mlp.fc2.weight, blocks.7.temporal_mlp.fc2.bias, blocks.8.temporal_norm1.weight, blocks.8.temporal_norm1.bias, blocks.8.temporal_attn.qkv.weight, blocks.8.temporal_attn.qkv.bias, blocks.8.temporal_attn.proj.weight, blocks.8.temporal_attn.proj.bias, blocks.8.temporal_norm2.weight, blocks.8.temporal_norm2.bias, blocks.8.temporal_mlp.fc1.weight, blocks.8.temporal_mlp.fc1.bias, blocks.8.temporal_mlp.fc2.weight, blocks.8.temporal_mlp.fc2.bias, blocks.9.temporal_norm1.weight, blocks.9.temporal_norm1.bias, blocks.9.temporal_attn.qkv.weight, blocks.9.temporal_attn.qkv.bias, blocks.9.temporal_attn.proj.weight, blocks.9.temporal_attn.proj.bias, blocks.9.temporal_norm2.weight, blocks.9.temporal_norm2.bias, blocks.9.temporal_mlp.fc1.weight, blocks.9.temporal_mlp.fc1.bias, blocks.9.temporal_mlp.fc2.weight, blocks.9.temporal_mlp.fc2.bias, blocks.10.temporal_norm1.weight, blocks.10.temporal_norm1.bias, blocks.10.temporal_attn.qkv.weight, blocks.10.temporal_attn.qkv.bias, blocks.10.temporal_attn.proj.weight, blocks.10.temporal_attn.proj.bias, blocks.10.temporal_norm2.weight, blocks.10.temporal_norm2.bias, blocks.10.temporal_mlp.fc1.weight, blocks.10.temporal_mlp.fc1.bias, blocks.10.temporal_mlp.fc2.weight, blocks.10.temporal_mlp.fc2.bias, blocks.11.temporal_norm1.weight, blocks.11.temporal_norm1.bias, blocks.11.temporal_attn.qkv.weight, blocks.11.temporal_attn.qkv.bias, blocks.11.temporal_attn.proj.weight, blocks.11.temporal_attn.proj.bias, blocks.11.temporal_norm2.weight, blocks.11.temporal_norm2.bias, blocks.11.temporal_mlp.fc1.weight, blocks.11.temporal_mlp.fc1.bias, blocks.11.temporal_mlp.fc2.weight, blocks.11.temporal_mlp.fc2.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "Unexpected keys (pre_logits.fc.bias, pre_logits.fc.weight, patch_embed.backbone.stages.0.blocks.0.conv1.weight, patch_embed.backbone.stages.0.blocks.0.conv2.weight, patch_embed.backbone.stages.0.blocks.0.conv3.weight, patch_embed.backbone.stages.0.blocks.0.downsample.conv.weight, patch_embed.backbone.stages.0.blocks.0.norm1.bias, patch_embed.backbone.stages.0.blocks.0.norm1.weight, patch_embed.backbone.stages.0.blocks.0.norm2.bias, patch_embed.backbone.stages.0.blocks.0.norm2.weight, patch_embed.backbone.stages.0.blocks.0.norm3.bias, patch_embed.backbone.stages.0.blocks.0.norm3.weight, patch_embed.backbone.stages.0.blocks.0.downsample.norm.bias, patch_embed.backbone.stages.0.blocks.0.downsample.norm.weight, patch_embed.backbone.stages.0.blocks.1.conv1.weight, patch_embed.backbone.stages.0.blocks.1.conv2.weight, patch_embed.backbone.stages.0.blocks.1.conv3.weight, patch_embed.backbone.stages.0.blocks.1.norm1.bias, patch_embed.backbone.stages.0.blocks.1.norm1.weight, patch_embed.backbone.stages.0.blocks.1.norm2.bias, patch_embed.backbone.stages.0.blocks.1.norm2.weight, patch_embed.backbone.stages.0.blocks.1.norm3.bias, patch_embed.backbone.stages.0.blocks.1.norm3.weight, patch_embed.backbone.stages.0.blocks.2.conv1.weight, patch_embed.backbone.stages.0.blocks.2.conv2.weight, patch_embed.backbone.stages.0.blocks.2.conv3.weight, patch_embed.backbone.stages.0.blocks.2.norm1.bias, patch_embed.backbone.stages.0.blocks.2.norm1.weight, patch_embed.backbone.stages.0.blocks.2.norm2.bias, patch_embed.backbone.stages.0.blocks.2.norm2.weight, patch_embed.backbone.stages.0.blocks.2.norm3.bias, patch_embed.backbone.stages.0.blocks.2.norm3.weight, patch_embed.backbone.stages.1.blocks.0.conv1.weight, patch_embed.backbone.stages.1.blocks.0.conv2.weight, patch_embed.backbone.stages.1.blocks.0.conv3.weight, patch_embed.backbone.stages.1.blocks.0.downsample.conv.weight, patch_embed.backbone.stages.1.blocks.0.norm1.bias, patch_embed.backbone.stages.1.blocks.0.norm1.weight, patch_embed.backbone.stages.1.blocks.0.norm2.bias, patch_embed.backbone.stages.1.blocks.0.norm2.weight, patch_embed.backbone.stages.1.blocks.0.norm3.bias, patch_embed.backbone.stages.1.blocks.0.norm3.weight, patch_embed.backbone.stages.1.blocks.0.downsample.norm.bias, patch_embed.backbone.stages.1.blocks.0.downsample.norm.weight, patch_embed.backbone.stages.1.blocks.1.conv1.weight, patch_embed.backbone.stages.1.blocks.1.conv2.weight, patch_embed.backbone.stages.1.blocks.1.conv3.weight, patch_embed.backbone.stages.1.blocks.1.norm1.bias, patch_embed.backbone.stages.1.blocks.1.norm1.weight, patch_embed.backbone.stages.1.blocks.1.norm2.bias, patch_embed.backbone.stages.1.blocks.1.norm2.weight, patch_embed.backbone.stages.1.blocks.1.norm3.bias, patch_embed.backbone.stages.1.blocks.1.norm3.weight, patch_embed.backbone.stages.1.blocks.2.conv1.weight, patch_embed.backbone.stages.1.blocks.2.conv2.weight, patch_embed.backbone.stages.1.blocks.2.conv3.weight, patch_embed.backbone.stages.1.blocks.2.norm1.bias, patch_embed.backbone.stages.1.blocks.2.norm1.weight, patch_embed.backbone.stages.1.blocks.2.norm2.bias, patch_embed.backbone.stages.1.blocks.2.norm2.weight, patch_embed.backbone.stages.1.blocks.2.norm3.bias, patch_embed.backbone.stages.1.blocks.2.norm3.weight, patch_embed.backbone.stages.1.blocks.3.conv1.weight, patch_embed.backbone.stages.1.blocks.3.conv2.weight, patch_embed.backbone.stages.1.blocks.3.conv3.weight, patch_embed.backbone.stages.1.blocks.3.norm1.bias, patch_embed.backbone.stages.1.blocks.3.norm1.weight, patch_embed.backbone.stages.1.blocks.3.norm2.bias, patch_embed.backbone.stages.1.blocks.3.norm2.weight, patch_embed.backbone.stages.1.blocks.3.norm3.bias, patch_embed.backbone.stages.1.blocks.3.norm3.weight, patch_embed.backbone.stages.2.blocks.0.conv1.weight, patch_embed.backbone.stages.2.blocks.0.conv2.weight, patch_embed.backbone.stages.2.blocks.0.conv3.weight, patch_embed.backbone.stages.2.blocks.0.downsample.conv.weight, patch_embed.backbone.stages.2.blocks.0.norm1.bias, patch_embed.backbone.stages.2.blocks.0.norm1.weight, patch_embed.backbone.stages.2.blocks.0.norm2.bias, patch_embed.backbone.stages.2.blocks.0.norm2.weight, patch_embed.backbone.stages.2.blocks.0.norm3.bias, patch_embed.backbone.stages.2.blocks.0.norm3.weight, patch_embed.backbone.stages.2.blocks.0.downsample.norm.bias, patch_embed.backbone.stages.2.blocks.0.downsample.norm.weight, patch_embed.backbone.stages.2.blocks.1.conv1.weight, patch_embed.backbone.stages.2.blocks.1.conv2.weight, patch_embed.backbone.stages.2.blocks.1.conv3.weight, patch_embed.backbone.stages.2.blocks.1.norm1.bias, patch_embed.backbone.stages.2.blocks.1.norm1.weight, patch_embed.backbone.stages.2.blocks.1.norm2.bias, patch_embed.backbone.stages.2.blocks.1.norm2.weight, patch_embed.backbone.stages.2.blocks.1.norm3.bias, patch_embed.backbone.stages.2.blocks.1.norm3.weight, patch_embed.backbone.stages.2.blocks.2.conv1.weight, patch_embed.backbone.stages.2.blocks.2.conv2.weight, patch_embed.backbone.stages.2.blocks.2.conv3.weight, patch_embed.backbone.stages.2.blocks.2.norm1.bias, patch_embed.backbone.stages.2.blocks.2.norm1.weight, patch_embed.backbone.stages.2.blocks.2.norm2.bias, patch_embed.backbone.stages.2.blocks.2.norm2.weight, patch_embed.backbone.stages.2.blocks.2.norm3.bias, patch_embed.backbone.stages.2.blocks.2.norm3.weight, patch_embed.backbone.stages.2.blocks.3.conv1.weight, patch_embed.backbone.stages.2.blocks.3.conv2.weight, patch_embed.backbone.stages.2.blocks.3.conv3.weight, patch_embed.backbone.stages.2.blocks.3.norm1.bias, patch_embed.backbone.stages.2.blocks.3.norm1.weight, patch_embed.backbone.stages.2.blocks.3.norm2.bias, patch_embed.backbone.stages.2.blocks.3.norm2.weight, patch_embed.backbone.stages.2.blocks.3.norm3.bias, patch_embed.backbone.stages.2.blocks.3.norm3.weight, patch_embed.backbone.stages.2.blocks.4.conv1.weight, patch_embed.backbone.stages.2.blocks.4.conv2.weight, patch_embed.backbone.stages.2.blocks.4.conv3.weight, patch_embed.backbone.stages.2.blocks.4.norm1.bias, patch_embed.backbone.stages.2.blocks.4.norm1.weight, patch_embed.backbone.stages.2.blocks.4.norm2.bias, patch_embed.backbone.stages.2.blocks.4.norm2.weight, patch_embed.backbone.stages.2.blocks.4.norm3.bias, patch_embed.backbone.stages.2.blocks.4.norm3.weight, patch_embed.backbone.stages.2.blocks.5.conv1.weight, patch_embed.backbone.stages.2.blocks.5.conv2.weight, patch_embed.backbone.stages.2.blocks.5.conv3.weight, patch_embed.backbone.stages.2.blocks.5.norm1.bias, patch_embed.backbone.stages.2.blocks.5.norm1.weight, patch_embed.backbone.stages.2.blocks.5.norm2.bias, patch_embed.backbone.stages.2.blocks.5.norm2.weight, patch_embed.backbone.stages.2.blocks.5.norm3.bias, patch_embed.backbone.stages.2.blocks.5.norm3.weight, patch_embed.backbone.stages.2.blocks.6.conv1.weight, patch_embed.backbone.stages.2.blocks.6.conv2.weight, patch_embed.backbone.stages.2.blocks.6.conv3.weight, patch_embed.backbone.stages.2.blocks.6.norm1.bias, patch_embed.backbone.stages.2.blocks.6.norm1.weight, patch_embed.backbone.stages.2.blocks.6.norm2.bias, patch_embed.backbone.stages.2.blocks.6.norm2.weight, patch_embed.backbone.stages.2.blocks.6.norm3.bias, patch_embed.backbone.stages.2.blocks.6.norm3.weight, patch_embed.backbone.stages.2.blocks.7.conv1.weight, patch_embed.backbone.stages.2.blocks.7.conv2.weight, patch_embed.backbone.stages.2.blocks.7.conv3.weight, patch_embed.backbone.stages.2.blocks.7.norm1.bias, patch_embed.backbone.stages.2.blocks.7.norm1.weight, patch_embed.backbone.stages.2.blocks.7.norm2.bias, patch_embed.backbone.stages.2.blocks.7.norm2.weight, patch_embed.backbone.stages.2.blocks.7.norm3.bias, patch_embed.backbone.stages.2.blocks.7.norm3.weight, patch_embed.backbone.stages.2.blocks.8.conv1.weight, patch_embed.backbone.stages.2.blocks.8.conv2.weight, patch_embed.backbone.stages.2.blocks.8.conv3.weight, patch_embed.backbone.stages.2.blocks.8.norm1.bias, patch_embed.backbone.stages.2.blocks.8.norm1.weight, patch_embed.backbone.stages.2.blocks.8.norm2.bias, patch_embed.backbone.stages.2.blocks.8.norm2.weight, patch_embed.backbone.stages.2.blocks.8.norm3.bias, patch_embed.backbone.stages.2.blocks.8.norm3.weight, patch_embed.backbone.stem.conv.weight, patch_embed.backbone.stem.norm.bias, patch_embed.backbone.stem.norm.weight, head.bias, head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Load pretrained Hybrid ViT weights from ./weights/ViT/vit_base_r50_s16_224.orig_in21k/jx_vit_base_resnet50_224_in21k-6f7c7740.pth\n",
      "âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: ./weights/MM-Det/current_model.pth\n",
      "âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ëª¨ë¸ ë¡œë”© ì‹œì‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "model = MMDet(config_dict)\n",
    "model.eval()\n",
    "\n",
    "# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
    "checkpoint_path = config.ckpt\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}\")\n",
    "    state_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "    \n",
    "    if 'model_state_dict' in state_dict:\n",
    "        state_dict = state_dict['model_state_dict']\n",
    "    \n",
    "    # State dict í‚¤ ì •ë¦¬\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if 'temporal_token' in k:\n",
    "            k = k.replace('temporal_token', 'fc_token')\n",
    "        new_state_dict[k.replace('module.', '')] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict, strict=config.cache_mm)\n",
    "    \n",
    "    # GPUë¡œ ì´ë™\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(\"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™\")\n",
    "    \n",
    "    print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(f\"âš ï¸ ê²½ê³ : ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}\")\n",
    "    print(\"ê¸°ë³¸ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì¶”ë¡  í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ íŒŒì¼ì— ëŒ€í•œ ë”¥í˜ì´í¬ ì˜ˆì¸¡\n",
    "    Returns: 0 (real) or 1 (fake)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ì²˜ëŸ¼ ì²˜ë¦¬ (ë‹¨ì¼ í”„ë ˆì„)\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡  ë¡œì§ êµ¬í˜„\n",
    "        # ì—¬ê¸°ì„œëŠ” placeholderë¡œ ëœë¤ ì˜ˆì¸¡\n",
    "        # ì‹¤ì œë¡œëŠ” ëª¨ë¸ì˜ forward ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ì•¼ í•¨\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # ì„ì‹œ êµ¬í˜„ - ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ ìœ¼ë¡œ êµì²´ í•„ìš”\n",
    "            prediction = np.random.choice([0, 1])\n",
    "        \n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        print(f\"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ ({image_path.name}): {e}\")\n",
    "        return 0  # ì˜¤ë¥˜ ì‹œ realë¡œ ì²˜ë¦¬\n",
    "\n",
    "\n",
    "def predict_video(video_path, model):\n",
    "    \"\"\"\n",
    "    ë¹„ë””ì˜¤ íŒŒì¼ì— ëŒ€í•œ ë”¥í˜ì´í¬ ì˜ˆì¸¡\n",
    "    Returns: 0 (real) or 1 (fake)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œ\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        frames = []\n",
    "        \n",
    "        frame_count = 0\n",
    "        max_frames = config.window_size * 4  # ìƒ˜í”Œë§ì„ ìœ„í•´ ì¶©ë¶„í•œ í”„ë ˆì„ ìˆ˜ì§‘\n",
    "        \n",
    "        while cap.isOpened() and frame_count < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "            frame_count += 1\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        if len(frames) == 0:\n",
    "            print(f\"ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path.name}\")\n",
    "            return 0\n",
    "        \n",
    "        # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡  ë¡œì§ êµ¬í˜„\n",
    "        # ì—¬ê¸°ì„œëŠ” placeholderë¡œ ëœë¤ ì˜ˆì¸¡\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # ì„ì‹œ êµ¬í˜„ - ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ ìœ¼ë¡œ êµì²´ í•„ìš”\n",
    "            prediction = np.random.choice([0, 1])\n",
    "        \n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        print(f\"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ ({video_path.name}): {e}\")\n",
    "        return 0  # ì˜¤ë¥˜ ì‹œ realë¡œ ì²˜ë¦¬\n",
    "\n",
    "\n",
    "print(\"âœ… ì¶”ë¡  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì „ì²´ ë°ì´í„° ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì¶”ë¡  ì‹œì‘\n",
      "================================================================================\n",
      "\n",
      "ì´ë¯¸ì§€ íŒŒì¼ ì¶”ë¡  ì¤‘... (ì´ 0ê°œ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì´ë¯¸ì§€ ì²˜ë¦¬: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë¹„ë””ì˜¤ íŒŒì¼ ì¶”ë¡  ì¤‘... (ì´ 0ê°œ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ë¹„ë””ì˜¤ ì²˜ë¦¬: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì¶”ë¡  ì™„ë£Œ! ì´ 0ê°œ íŒŒì¼ ì²˜ë¦¬\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ì¶”ë¡  ì‹œì‘\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¶”ë¡ \n",
    "print(f\"\\nì´ë¯¸ì§€ íŒŒì¼ ì¶”ë¡  ì¤‘... (ì´ {len(image_files)}ê°œ)\")\n",
    "for img_path in tqdm(image_files, desc=\"ì´ë¯¸ì§€ ì²˜ë¦¬\"):\n",
    "    prediction = predict_image(img_path, model)\n",
    "    results.append({\n",
    "        'filename': img_path.name,\n",
    "        'label': int(prediction)\n",
    "    })\n",
    "\n",
    "# ë¹„ë””ì˜¤ ì¶”ë¡ \n",
    "print(f\"\\në¹„ë””ì˜¤ íŒŒì¼ ì¶”ë¡  ì¤‘... (ì´ {len(video_files)}ê°œ)\")\n",
    "for video_path in tqdm(video_files, desc=\"ë¹„ë””ì˜¤ ì²˜ë¦¬\"):\n",
    "    prediction = predict_video(video_path, model)\n",
    "    results.append({\n",
    "        'filename': video_path.name,\n",
    "        'label': int(prediction)\n",
    "    })\n",
    "\n",
    "print(f\"\\nâœ… ì¶”ë¡  ì™„ë£Œ! ì´ {len(results)}ê°œ íŒŒì¼ ì²˜ë¦¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. submission.csv ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m submission_df = pd.DataFrame(results)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ë°ì´í„° íƒ€ì… í™•ì¸\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m submission_df[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43msubmission_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfilename\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      6\u001b[39m submission_df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m] = submission_df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# submission.csv ì €ì¥\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'filename'"
     ]
    }
   ],
   "source": [
    "# DataFrame ìƒì„±\n",
    "submission_df = pd.DataFrame(results)\n",
    "\n",
    "# ë°ì´í„° íƒ€ì… í™•ì¸\n",
    "submission_df['filename'] = submission_df['filename'].astype(str)\n",
    "submission_df['label'] = submission_df['label'].astype(int)\n",
    "\n",
    "# submission.csv ì €ì¥\n",
    "submission_df.to_csv(config.output_path, index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"submission.csv ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"ì €ì¥ ê²½ë¡œ: {config.output_path}\")\n",
    "print(f\"ì „ì²´ ë°ì´í„° ìˆ˜: {len(submission_df)}\")\n",
    "print(f\"\\në¼ë²¨ ë¶„í¬:\")\n",
    "print(f\"  Real (0): {(submission_df['label'] == 0).sum()}ê°œ\")\n",
    "print(f\"  Fake (1): {(submission_df['label'] == 1).sum()}ê°œ\")\n",
    "print(\"\\nìƒ˜í”Œ ë°ì´í„°:\")\n",
    "print(submission_df.head(10))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# íŒŒì¼ ì €ì¥ í™•ì¸\n",
    "if os.path.exists(config.output_path):\n",
    "    file_size = os.path.getsize(config.output_path)\n",
    "    print(f\"âœ… íŒŒì¼ í¬ê¸°: {file_size:,} bytes\")\n",
    "else:\n",
    "    print(\"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. AI Factory ì œì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AI Factory ì œì¶œ\n",
      "================================================================================\n",
      "file : task\n",
      "jupyter notebook\n"
     ]
    }
   ],
   "source": [
    "# AI Factory ì œì¶œ\n",
    "import aifactory.score as aif\n",
    "\n",
    "# âš ï¸ ì£¼ì˜: ì‹¤ì œ ì œì¶œì‹œ ë§ˆì´í˜ì´ì§€ì—ì„œ ë°œê¸‰ë°›ì€ KEYë¥¼ ì…ë ¥í•˜ì„¸ìš”!\n",
    "MY_KEY = \"46bccc74-df80-48e5-9d4a-42920f87903f\"  # â† ì—¬ê¸°ì— ì‹¤ì œ KEY ì…ë ¥\n",
    "MODEL_NAME = \"MM-Det-DeepfakeDetector\"  # ëª¨ë¸ ì´ë¦„\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI Factory ì œì¶œ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # ì œì¶œ\n",
    "    aif.submit(\n",
    "        model_name=MODEL_NAME,\n",
    "        key=MY_KEY\n",
    "    )\n",
    "    print(\"âœ… ì œì¶œ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì œì¶œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"submission.csv íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ê²°ê³¼ ì €ì¥ (ë°±ì—…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í´ë”ì—ë„ ê²°ê³¼ ë°±ì—…\n",
    "import shutil\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(config.model_dir, exist_ok=True)\n",
    "\n",
    "# submission.csv ë°±ì—…\n",
    "backup_path = os.path.join(config.model_dir, 'submission_backup.csv')\n",
    "shutil.copy(config.output_path, backup_path)\n",
    "\n",
    "# ì‹¤í—˜ ì •ë³´ ì €ì¥\n",
    "experiment_info = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'model_name': config.model_name,\n",
    "    'checkpoint': config.ckpt,\n",
    "    'total_files': len(submission_df),\n",
    "    'image_files': len(image_files),\n",
    "    'video_files': len(video_files),\n",
    "    'predictions': {\n",
    "        'real': int((submission_df['label'] == 0).sum()),\n",
    "        'fake': int((submission_df['label'] == 1).sum())\n",
    "    },\n",
    "    'pytorch_version': torch.__version__,\n",
    "    'cuda_available': torch.cuda.is_available(),\n",
    "}\n",
    "\n",
    "info_path = os.path.join(config.model_dir, 'experiment_info.json')\n",
    "with open(info_path, 'w') as f:\n",
    "    json.dump(experiment_info, f, indent=2)\n",
    "\n",
    "print(\"âœ… ê²°ê³¼ ë°±ì—… ì™„ë£Œ\")\n",
    "print(f\"  - {backup_path}\")\n",
    "print(f\"  - {info_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì™„ë£Œ! ğŸ‰\n",
    "\n",
    "### ìƒì„±ëœ íŒŒì¼:\n",
    "- `submission.csv`: AI Factory ì œì¶œìš© íŒŒì¼\n",
    "- `model/deep-fake-detector-v2-model/submission_backup.csv`: ë°±ì—… íŒŒì¼\n",
    "- `model/deep-fake-detector-v2-model/experiment_info.json`: ì‹¤í—˜ ì •ë³´\n",
    "\n",
    "### ì œì¶œ ë°©ë²•:\n",
    "1. ìœ„ì˜ \"10. AI Factory ì œì¶œ\" ì…€ì—ì„œ API KEYë¥¼ ì…ë ¥\n",
    "2. ì…€ì„ ì‹¤í–‰í•˜ì—¬ ìë™ ì œì¶œ\n",
    "3. ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ `submission.csv` íŒŒì¼ì„ ì œì¶œ\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­:\n",
    "- ì¶”ë¡  ì‹œê°„ì€ ìµœëŒ€ 3ì‹œê°„ê¹Œì§€ í—ˆìš©ë©ë‹ˆë‹¤\n",
    "- submission.csv í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš” (filename: ë¬¸ìì—´, label: ì •ìˆ˜)\n",
    "- í‰ê°€ ì§€í‘œ: Macro F1-score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
